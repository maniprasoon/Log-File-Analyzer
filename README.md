# ğŸ“Š Log File Analyzer for IT Operations

A **production-ready Python-based log analysis system** with a modern web dashboard and historical tracking. Designed for large-scale server logs, this system delivers **actionable insights, performance metrics, and visual intelligence** for IT operations, security teams, and capacity planners.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-ORM-orange.svg)
![License](https://img.shields.io/badge/License-MIT-lightgrey.svg)

---

## ğŸš€ Features

### Core Analysis Engine

* âš¡ **High-Performance Parsing** â€“ Processes 50,000+ log lines in seconds
* ğŸ›¡ï¸ **Robust Error Handling** â€“ Gracefully handles malformed log entries
* ğŸ’¾ **Memory Efficient** â€“ Chunk-based processing for large log files
* ğŸ“ˆ **Comprehensive Metrics** â€“ Error rates, top IPs, request patterns, trends

### Advanced Capabilities

* ğŸ—ƒï¸ **Historical Database** â€“ SQLite storage with SQLAlchemy ORM
* ğŸŒ **Web Dashboard** â€“ Real-time Flask-based dashboard
* ğŸ“Š **Interactive Visualizations** â€“ Matplotlib charts with trend analysis
* ğŸ“‹ **Automated Reporting** â€“ Text + visual reports generation
* ğŸ” **Smart Pattern Detection** â€“ Regex-based parsing with fallback support

### Production Ready

* ğŸ“ Execution & audit logging
* âš™ï¸ Centralized configuration management
* ğŸ§ª Test data generator for realistic logs
* ğŸ¨ Professional, responsive UI

---

## ğŸ“ Project Structure

```
log_analyzer/
â”œâ”€â”€ log_generator.py          # Generate realistic log data
â”œâ”€â”€ log_analyzer.py           # Main analyzer with chunk processing
â”œâ”€â”€ log_parser.py             # Optimized regex parser with fallback
â”œâ”€â”€ report_generator.py       # Visualizations and text reports
â”œâ”€â”€ database.py               # SQLAlchemy ORM for historical data
â”œâ”€â”€ app.py                    # Flask web dashboard
â”œâ”€â”€ config.py                 # Centralized configuration
â”œâ”€â”€ templates/dashboard.html  # Web interface
â”œâ”€â”€ static/style.css          # Dashboard styling
â”œâ”€â”€ requirements.txt          # Dependencies
â””â”€â”€ README.md                 # Documentation
```

---

## ğŸ—ï¸ Architecture Overview

![Architecture](https://res.cloudinary.com/ds8fnrk7s/image/upload/v1768973855/deepseek_mermaid_20260121_0b9143_wnpflx.png)


---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/log-analyzer.git
cd log-analyzer
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Mac / Linux
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Quick Start

### Step 1: Generate Sample Logs

```bash
python log_generator.py
```

Generates **50,000+ realistic log entries** with varied IPs, HTTP methods, URLs, and error patterns.

---

### Step 2: Run Analysis

```bash
python log_analyzer.py
```

**Outputs Generated:**

* âœ… **Text Report:** `log_analysis_report.txt`
* ğŸ“Š **Charts:** `reports/log_analysis_dashboard.png`
* ğŸ—ƒï¸ **Database:** `log_analysis.db` (auto-created)
* ğŸ“ **Execution Logs:** `logs/analysis.log`

---

### Step 3: Launch Web Dashboard

```bash
python app.py
```

Visit: **[http://127.0.0.1:5000](http://127.0.0.1:5000)**

---

## ğŸ“Š Sample Output

### Console Summary

```
============================================================
LOG ANALYSIS SUMMARY
============================================================
Total Requests: 50,000
Total Errors: 7,543
Error Rate: 15.09%
Execution Time: 2.45 seconds

Top Error Codes:
  404: 3,234 occurrences
  500: 1,890 occurrences
  403: 1,234 occurrences
  401: 789 occurrences
  400: 396 occurrences

Top 5 IPs with Errors:
  192.168.1.100: 542 errors
  10.0.0.25: 421 errors
  172.16.254.1: 389 errors
  192.168.0.15: 312 errors
  10.0.0.42: 287 errors
============================================================
```

---

## ğŸŒ Web Dashboard Features

* ğŸ“ˆ Error rate trends over time
* ğŸ“Š Top error sources visualization
* ğŸ”¢ Statistical summary cards
* ğŸ“‹ Recent analysis history table
* ğŸ”„ Auto-refresh every 60 seconds

---

## ğŸ› ï¸ Key Technologies

| Component       | Technology           | Purpose                               |
| --------------- | -------------------- | ------------------------------------- |
| Parsing Engine  | Regex + Pandas       | Fast, memory-efficient log processing |
| Database        | SQLAlchemy + SQLite  | Historical data persistence           |
| Web Framework   | Flask                | Lightweight dashboard                 |
| Visualization   | Matplotlib + Seaborn | Professional charts                   |
| Data Generation | Faker                | Realistic test data                   |
| Configuration   | Python-dotenv        | Environment management                |

---

## ğŸ”§ Advanced Configuration

Edit `config.py` to customize system behavior:

```python
# Performance tuning
CHUNK_SIZE = 10000  # Lines per chunk for memory management

# Analysis parameters
ERROR_CODES = {'400', '401', '403', '404', '500'}
TOP_IPS_COUNT = 10

# Dashboard settings
HOST = "0.0.0.0"
PORT = 8080
```

---

## ğŸ“ˆ Performance Metrics

| Metric              | Result                 |
| ------------------- | ---------------------- |
| Processing Speed    | ~20,000 lines / second |
| Memory Usage        | < 100MB for 100K lines |
| Database Operations | < 50ms per query       |
| Dashboard Load Time | < 2 seconds            |

---

## ğŸ¯ Use Cases

### IT Operations

* Monitor server error rates in real time
* Identify misbehaving or malicious IPs
* Track system performance trends

### Security Analysis

* Detect unusual access patterns
* Identify brute-force attempts
* Monitor suspicious activities

### Capacity Planning

* Analyze request volume patterns
* Predict future infrastructure needs
* Optimize server configurations

---

## ğŸ“š API Reference

### REST Endpoints

| Endpoint        | Method | Description                 |
| --------------- | ------ | --------------------------- |
| `/`             | GET    | Main dashboard              |
| `/api/analyses` | GET    | Recent analysis data (JSON) |
| `/api/stats`    | GET    | Statistics summary (JSON)   |
| `/health`       | GET    | Health check                |

### Database Schema

```sql
CREATE TABLE analysis_results (
    id INTEGER PRIMARY KEY,
    timestamp DATETIME,
    total_requests INTEGER,
    total_errors INTEGER,
    error_rate FLOAT,
    error_distribution TEXT,
    top_error_ips TEXT,
    execution_time FLOAT
);
```

---

## ğŸ” Log Format Support

**Default Format**

```
YYYY-MM-DD HH:MM:SS IP_ADDRESS HTTP_METHOD URL STATUS_CODE
```

**Extensible To:**

* JSON logs
* CSV logs
* Apache / Nginx formats
* Custom application logs

---

## ğŸ§ª Testing Workflow

```bash
python log_generator.py
python log_analyzer.py
python log_analyzer.py
python app.py
```

---

## ğŸš€ Scaling Considerations

### Production Enhancements

* PostgreSQL / MySQL
* Redis caching
* Celery for async processing
* Prometheus monitoring
* JWT / API key authentication


## ğŸ“„ License

MIT License

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## â­ Support

If this project helps you, consider starring â­ the repository.


ğŸ“¸ **Screenshots**
![Dashboard](https://res.cloudinary.com/ds8fnrk7s/image/upload/v1768973875/Screenshot_2026-01-21_101005_ydeiom.png)
![webpage](https://res.cloudinary.com/ds8fnrk7s/image/upload/v1768973876/Screenshot_2026-01-21_105842_w4xx56.png)


